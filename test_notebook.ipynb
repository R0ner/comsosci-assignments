{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd227a2-798d-4cac-822e-1caee21bbf19",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524f9398-3115-4fa3-a894-aa25ebfb4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba204a-e28f-49d2-9fd6-63f3035de403",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "\n",
    "We use a test corpus consisting of three different courses: \n",
    "10031, 01005 and 23932.\n",
    "\n",
    "A document in the corpus is 'General course objectives' + 'Learning objectives' + 'Content'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f57ba4-70b4-47cd-a035-f40f933dc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tuple(course, path)\n",
    "raw_text_paths = [('01005', 'documents_test/01005.txt'), ('23932', 'documents_test/23932.txt'), ('10031', 'documents_test/10031.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df31eca7-7983-4f93-8fd4-e8c5f4e9e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>The course content is the mathematical basis f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23932</th>\n",
       "      <td>The students should, based on the cell, acquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>The overall goal is to give Physics and Nanote...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "01005  The course content is the mathematical basis f...\n",
       "23932  The students should, based on the cell, acquir...\n",
       "10031  The overall goal is to give Physics and Nanote..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text_dict = {}\n",
    "\n",
    "for course, raw_text_path in raw_text_paths:\n",
    "    with open(raw_text_path, 'r') as file:\n",
    "        raw_text_dict[course] = [file.read().replace('\\n', ' ')]\n",
    "\n",
    "courses = pd.DataFrame.from_dict(raw_text_dict, orient='index', columns=['text'])\n",
    "\n",
    "courses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5320f8-7111-44b7-bef9-bbb25de478db",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ed0450-68b0-496b-93c4-20bfa3b6e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words are removed from the tokenized text. We get the stop words here.\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words = [re.sub('[^a-z_-]', '', stop_word) for stop_word in stop_words]\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Tokenizer function. \n",
    "    The following is removed from the tokenized text:\n",
    "    Symbols, stop words.\n",
    "    \n",
    "    Finally, only unique words are included in the tokens (ie. no repeats)\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-z]', ' ', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2962da-1b05-4587-bd59-e766b697ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>The course content is the mathematical basis f...</td>\n",
       "      <td>[course, content, mathematical, basis, broad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23932</th>\n",
       "      <td>The students should, based on the cell, acquir...</td>\n",
       "      <td>[students, based, cell, acquire, basic, unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>The overall goal is to give Physics and Nanote...</td>\n",
       "      <td>[overall, goal, give, physics, nanotechnology,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "01005  The course content is the mathematical basis f...   \n",
       "23932  The students should, based on the cell, acquir...   \n",
       "10031  The overall goal is to give Physics and Nanote...   \n",
       "\n",
       "                                                  tokens  \n",
       "01005  [course, content, mathematical, basis, broad, ...  \n",
       "23932  [students, based, cell, acquire, basic, unders...  \n",
       "10031  [overall, goal, give, physics, nanotechnology,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tokenized text is saved in a new column\n",
    "courses['tokens'] = courses.apply(lambda row: tokenize(row['text']), axis=1)\n",
    "courses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625edaf8-d552-482b-8ed4-8c78f8d6df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus wich is a dictionary of the tokenized texts\n",
    "corpus = courses['tokens'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b4724-313b-4a0f-8242-298aa0fc5bb6",
   "metadata": {},
   "source": [
    "# TF-IDF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27521ac6-6b03-4191-a95c-d24f94a7c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document: list) -> tuple[np.array, np.array]:\n",
    "    \"\"\"This function calculates the term frequency of a document.\n",
    "    The term frequency is normalized by the total number of words in the document.\n",
    "    Returns a tuple of arrays. The first array is the terms and the second array is\n",
    "    the term frequency in the same order.\n",
    "    \n",
    "    Arguments:\n",
    "        document (np.array): array of tokens.\n",
    "    \"\"\"\n",
    "    fdist = nltk.FreqDist(document)\n",
    "    n_words = fdist.N()\n",
    "    terms = np.array(list(fdist.keys()))\n",
    "    tf = np.array(list(fdist.values())) / n_words\n",
    "    \n",
    "    return tf, terms\n",
    "\n",
    "\n",
    "def inverse_document_frequency(documents: dict[list], corpus=None) -> dict[float]:\n",
    "    \"\"\"This function computes the inverse document frequency (idf) given\n",
    "    a list of documents and a set of terms.\n",
    "    \"\"\"\n",
    "    if corpus is None:\n",
    "        corpus = documents.keys()\n",
    "    \n",
    "    n_documents = len(corpus)\n",
    "    terms, counts = np.unique(\n",
    "        np.concatenate([list(set(documents[d])) for d in corpus]),\n",
    "        return_counts=True\n",
    "    )\n",
    "    \n",
    "    idf = np.log(n_documents / (counts))\n",
    "    idf_lookup = {term: w for term, w in zip(terms, idf)}\n",
    "    \n",
    "    return idf_lookup\n",
    "\n",
    "def tf_idf(document: list, idf_lookup: dict[float]) -> tuple[np.array, np.array]:\n",
    "    \"\"\"Computes the tf-idf of a document, given a document and a lookup table for idf.\"\"\"\n",
    "    tf, terms = term_frequency(document)\n",
    "    idf = np.array([idf_lookup[term] for term in terms])\n",
    "    \n",
    "    return tf * idf, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70c1792-d040-4cda-89f8-5c617dbad188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 terms sorted by term frequency (TF):\n",
      "01005:\n",
      "['use' 'linear' 'equations' 'functions' 'applications']\n",
      "23932:\n",
      "['biological' 'cell' 'describe' 'structure' 'students']\n",
      "10031:\n",
      "['physics' 'sections' 'well' 'technology' 'within']\n"
     ]
    }
   ],
   "source": [
    "# Top 5 words, TF\n",
    "print('Top 5 terms sorted by term frequency (TF):')\n",
    "\n",
    "for course, document in corpus.items():\n",
    "    tf, terms = term_frequency(document)\n",
    "    sorted_indices = np.argsort(tf)[::-1]\n",
    "    stock_top_5 = terms[sorted_indices[:5]]\n",
    "    print(f'{course}:')\n",
    "    print(stock_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37cd1b98-0b70-41e3-b38a-f2a17601778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_lookup = inverse_document_frequency(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a3b72e-dd89-41cf-a9f9-0841dcd4fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 terms sorted by term frequency (TF):\n",
      "01005:\n",
      "['use' 'linear' 'equations' 'functions' 'applications' 'elementary'\n",
      " 'mathematical' 'systems' 'complex' 'differential']\n",
      "23932:\n",
      "['biological' 'cell' 'describe' 'structure' 'students' 'basic' 'processes'\n",
      " 'explain' 'regulation' 'mechanisms']\n",
      "10031:\n",
      "['physics' 'sections' 'well' 'technology' 'within' 'subjects' 'laboratory'\n",
      " 'work' 'data' 'engineering']\n",
      "\n",
      "\n",
      "Top 10 terms sorted by TF-IDF:\n",
      "01005:\n",
      "['linear' 'equations' 'elementary' 'applications' 'differential'\n",
      " 'mathematical' 'systems' 'complex' 'mathematics' 'vector']\n",
      "23932:\n",
      "['biological' 'cell' 'describe' 'basic' 'processes' 'regulation'\n",
      " 'mechanisms' 'living' 'energy' 'pro']\n",
      "10031:\n",
      "['physics' 'sections' 'subjects' 'data' 'group' 'ultrafast' 'optical'\n",
      " 'pulses' 'hydrodynamics' 'lab']\n"
     ]
    }
   ],
   "source": [
    "# Top 10 words, TF\n",
    "print('Top 10 terms sorted by term frequency (TF):')\n",
    "\n",
    "topx = 10\n",
    "for course, document in corpus.items():\n",
    "    tf, terms = term_frequency(document)\n",
    "    sorted_indices = np.argsort(tf)[::-1]\n",
    "    stock_top_10 = terms[sorted_indices[:topx]]\n",
    "    # print(tf[sorted_indices[:topx]])\n",
    "    print(f'{course}:')\n",
    "    print(stock_top_10)\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "# Top 10 words, TF-IDF\n",
    "print('Top 10 terms sorted by TF-IDF:')\n",
    "\n",
    "for course, document in corpus.items():\n",
    "    tfidf, terms = tf_idf(document, idf_lookup)\n",
    "    sorted_indices = np.argsort(tfidf)[::-1]\n",
    "    stock_top_10 = terms[sorted_indices[:topx]]\n",
    "    # print(tfidf[sorted_indices[:topx]])\n",
    "    print(f'{course}:')\n",
    "    print(stock_top_10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
